---
title: "Running ICBM"
author: "Francis Durnin-Vermette"
date: "2022/12/19"
output:
  html_notebook:
    toc: true
    number_sections: true
    df_print: paged
bibliography: re.bib
editor_options:
  chunk_output_type: inline
---

```{r include=FALSE}

library(ggplot2)
library(knitr)
library(dplyr)
library(geojson)
library(tibble)
library(purrr)
library(stringr)
library(here)
library(lubridate)
library(tidyr)

dir.create(tempdir()) #This fixes a bug if the temporary directory is not found

here::i_am("walkthrough_icbm.rmd")
source(here::here("re_script.r"))
source(here::here("re_functions.r"))
source(here::here("run_icbm_and_re.r"))
source(here::here("get_climate_data.r"))

```


# ICBM
ICBM simulations can be run using the function `RunICBMAndRe()` from the script `run_icbm_and_re.r`.
These simulations include the r~e~ parameter calculated from daily climate data.
The definitions of every input are given in the header of that script.
The function returns a similar output as the original ICBM function `icbm_holos4_classic_manure()`:
a table with ICBM C pools for every year, as well as the yearly mean r~e~ value.

## Reading input data

### Site data
```{r}
# We need to add SLC polygon IDs to the sitedata because this is how climate data is linked to site data.
# read SLC polygon IDs
polyids_all <- readr::read_csv(here("climate_data","Documentation", "SLC_PCPTREGION.csv"))
# read site data
sitedata_all <- readr::read_csv("all_experiments_dummy.csv") %>%
    left_join(polyids_all, by=c("latitude" = "Lat", "longitude" = "Long"))
```

### Climate data
To run ICBM with the r~e~ calculator, the climate data should have these mandatory columns: `Year`, `JulianDay`, `Tavg`, which is the mean daily air temperature, `PREC`, which is the mean daily precipitation, and `PET`, which is the mean daily PET.

We can use the function `getClimateData()` to fetch the relevant climate data, and format it according to the above requirements.

Note: use `suppressWarnings()` to run a function without any warnings.

```{r}
climatedata <- getClimateData(climate_data_directory = here("climate_data","W9param_TablesCleaned"))
climatedata
```


## Running the model on one site
For this example, we are only looking at one treatment from the experiment conducted at the Ellerslie site.
```{r}
sitedata_ex_onesite <- sitedata_all %>%
    filter(location_name == "Ellerslie") %>%
	filter(treatment_number == 7) %>%
	filter(year_name <= 1985)
```
To run the model, we can simply pass the site and climate data to `RunICBMAndRe()`.
`ag_init`, `bg_init`, and `o_init` are initial C contents of those three pools,
and `irrigation_use_estimate` is a TRUE/FALSE value indicating whether you want daily irrigation values to be estimated based on site location.
```{r}
result_ex_onesite <- RunICBMAndRe(
	SiteDataTable = sitedata_ex_onesite,
	DailyClimateTable = climatedata,
	ag_init = 0,
	bg_init = 0,
	o_init = 0)
result_ex_onesite
```

```{r}
setwd("C:/Users/durenvermettef/Documents/ICBM-re-calculator")
SiteDataTable = sitedata_ex_onesite
DailyClimateTable = climatedata
ag_init = 0
bg_init = 0
o_init = 0
irrigation_use_estimate = FALSE

alfa = 0.7
SoilTopThickness = 250
Temp_min = -3.78
Temp_max = 30
r_s = 0.42
r_wp = 0.18
ReferenceAdjustment = 0.10516

r_c = NA
tillage_soil = "Brown"
tillage_type = "Intensive Tillage"
irrigation_region = "Canada"
irrigation_use_estimate = FALSE
irrigation = 0

yield = filter(SiteDataTable, year_name == 1983)$total_yield
perennial = filter(SiteDataTable, year_name == 1983)$perennial
SoilOrganicC_Percent = filter(SiteDataTable, year_name == 1983)$soil_total_carbon_px
ClayContent = filter(SiteDataTable, year_name == 1983)$clay_px
SandContent = filter(SiteDataTable, year_name == 1983)$sand_px
```
## Running ICBM for multiple treatments on the same site
In this example, we want to simulate every treatment at the Ellerslie site.
In order to do this, we `group_by` treatment, and then split each of the groups into a seperate table using `group_split`.
This leaves us with a list of site data tables that we will pass iteratively into `RunICBMAndRe`.

```{r}
sitedata_ex_multipletrmt <- sitedata_all %>%
	filter(year_name <= 1985) %>%
	filter(location_name == "Ellerslie") %>%
	group_by(treatment_name) %>%
	group_split
```

We use the `map` function (from the library `purrr`) to pass each list element of `sitedata_ex_multipletrmt` into `RunICBMAndRe`.

More information about how `purrr` and `map` work can be found here: https://purrr.tidyverse.org/reference/map.html
```{r}
result_ex_multipletrmt <- sitedata_ex_multipletrmt %>%
	map(function(x) {
			RunICBMAndRe(
			SiteDataTable = x,
			DailyClimateTable = climatedata,
			ag_init = 0,
			bg_init = 0,
			o_init = 0)
		}
	)
result_ex_multipletrmt
```

In the `map` function, `~` is shorthand for defining the function that we will iterate through, and `.` refers to the current element of the iteration.
Using these shorthands, we can simplify this process:
```{r}
result_ex_multipletrmt <- sitedata_ex_multipletrmt %>%
	map(~RunICBMAndRe(
	SiteDataTable = .,
	DailyClimateTable = climatedata,
	ag_init = 0,
	bg_init = 0,
	o_init = 0))
result_ex_multipletrmt
```


## Running ICBM for multiple sites/teams
Data for specific teams and from specific locations can be acquired using `filter`:
```{r}
sitedata_ex_multiplesite <- sitedata_all %>%
	filter(year_name > 1990) %>%
	filter(year_name < 2005) %>%
	filter(team_name == "A") %>%
	filter(location_name %in% c("Ellerslie", "Harrow")) %>%
	group_by(location_name, treatment_name, replication_number) %>%
	group_split
	
```
```{r}
result_ex_multiplesite <- sitedata_ex_multiplesite %>%
	map(~RunICBMAndRe(
	SiteDataTable = .,
	DailyClimateTable = climatedata,
	ag_init = 0,
	bg_init = 0,
	o_init = 0))
result_ex_multiplesite
```

### Grouping errors
Each input to `RunICBMAndRe()` is a seperate model run, and so needs to have consecutive years.
Otherwise, an error is returned:
```{r}
sitedata_ex_error1 <- sitedata_all %>%
	filter(team_name == "B") %>%
	filter(year_name >= 1981) %>%
	group_by(location_name) %>%
	group_split
```
```{r}
try(sitedata_ex_error1 %>%
	map(~RunICBMAndRe(
	SiteDataTable = .,
	DailyClimateTable = climatedata,
	ag_init = 0,
	bg_init = 0,
	o_init = 0)))
```

We can see the problem by looking to see if there are any duplicated years in our list elements:

```{r}
sitedata_ex_error1 %>%
	map(~any(duplicated(.$year_name))) %>%
	unlist
```
This shows that in both of our groups, there are duplicated years, which is an invalid input to `RunICBMAndRe`.
In contrast, in one of our previous examples there are no instances of duplicated years:
```{r}
sitedata_ex_multiplesite %>%
	map(~any(duplicated(.$year_name))) %>%
	unlist
```

This problem can be fixed by changing our site data groupings.
We need to make sure our groups encompass every permutation of the experiments we are looking at.
In the examples above, we only needed to add location_name, treatment_name, and replication_number in order to achieve valid groupings.
However, this does not work for all sites:
```{r}
sitedata_ex_error2 <- sitedata_all %>%
	filter(team_name == "B") %>%
	filter(year_name >= 1981) %>%
	group_by(team_name, location_name, treatment_name, replication_number) %>%
	group_split
sitedata_ex_error2 %>%
	map(~any(duplicated(.$year_name))) %>%
	unlist

```

In these sites, there are actually two other grouping variables that we need to account for: soil depth and plot id.

In our dataset, soil_depth_min_cm and soil_depth_max_cm are in seperate columns.
To create a grouping variable for soil depth, we concatenate these two columns into a single soil depth column, and then add this as a new group.

Then, by adding soil_depth as well as plot_id to our grouping variables, we arrive at valid inputs to the model:
```{r}
sitedata_ex_depth <- sitedata_all %>%
	filter(team_name == "B") %>%
	filter(year_name >= 1981) %>%
	mutate(soil_depth = paste0(soil_depth_min_cm,"-",soil_depth_max_cm)) %>%
	group_by(team_name, location_name, treatment_name, replication_number, plot_id, soil_depth) %>%
	group_split
sitedata_ex_depth %>%
	map(~any(duplicated(.$year_name))) %>%
	unlist
```

```{r}
result_ex_depth <- sitedata_ex_depth[1:10] %>%
	map(~RunICBMAndRe(
	SiteDataTable = .,
	DailyClimateTable = climatedata,
	ag_init = 0,
	bg_init = 0,
	o_init = 0))
result_ex_depth
```

Other possible columns that could lead to problems with grouping include `field_name`, `block`, etc.

## Running ICBM using parellel computing

## Running ICBM using parameter overrides
Certain parameters need to be overridden in order to perform calibrations or sensitivity analyses.
This can be done by passing the parameters to override directly into the `RunICBMAndRe` wrapper function.

Constant parameters (e.g. `SoilTopThickness`, default = 250) and parameters that are inputted as part of an external data table (e.g. `PREC` from the climate data table, no default) can both be overridden.

```{r}
result_ex_multipletrmt <- sitedata_ex_multipletrmt %>%
	map(~RunICBMAndRe(
	SiteDataTable = .,
	DailyClimateTable = climatedata,
	ag_init = 0,
	bg_init = 0,
	o_init = 0,
	# overrides
	hag = 0.1))
result_ex_multipletrmt
```

### Optimizing a parameter using `optim`
To demonstrate a practical example of using parameter overrides, we will use the built-in `optim` function.

`optim` passes a vector to the function you define, and finds the values that minimize this function.
The vector can have names, and these names are also passed to the function, which allows us to override parameters based on name.

```{r}
ex_func <- function(parameters) {
    parameters["x"] + parameters["y"]
}
optim(par = c(x=-1.2,y=1), fn = ex_func, method = "L-BFGS-B", lower = c(x=0,y=1), upper = c(x=1,y=5))
```

In order to use optimization functions such as this with SOC models, we usually need to write a small wrapper function that translates inputs/outputs of our model script for use by the optimization function.
In this case, the parameters that we are interested in optimizing are passed as the first argument of the function.

This function runs the model, finds the mean r~e~ between years, and returns that value.
Therefore, by passing this function to `optim`, we will be asking it to minimize the value of r~e~.
In practice, you will want to write a wrapper function that computes model error.

```{r}
icbm_wrapper_example <- function(parameters,
DailyClimateTable,
                SiteDataTable,
                ag_init = 0,
                bg_init = 0,
                o_init = 0,
                ...) {
					args <- list(...)

					inputs <- list(DailyClimateTable = DailyClimateTable,
					SiteDataTable = SiteDataTable,
					ag_init = ag_init,
					bg_init = bg_init,
					o_init = o_init) %>%
					append(args) %>%
					append(as.list(parameters))

					model_results <- do.call(RunICBMAndRe,inputs)

					mean_re <- mean(bind_rows(model_results)$re)

					print(paste0(names(parameters),": ",parameters))
					print(paste0("mean_re: ",mean_re))
					return(mean_re)
				}
```
We can override a parameter using the first argument by hand, or pass the whole function into the `optim` function.
```{r}
	icbm_wrapper_example(
		parameters = c(r_c = 1),
	SiteDataTable = sitedata_ex_multipletrmt[[1]],
	DailyClimateTable = climatedata,
	ag_init = 0,
	bg_init = 0,
	o_init = 0
	)

optim(par = c(r_c = 0.5), fn = icbm_wrapper_example, method = "L-BFGS-B", lower = c(r_c = 0), upper = c(r_c = 1), SiteDataTable = sitedata_ex_multipletrmt[[1]], DailyClimateTable = climatedata)
```
We can optimize for multiple parameters
```{r}
optim(par = c(r_c = 0.5, hag = 0.1), fn = icbm_wrapper_example, method = "L-BFGS-B", lower = c(r_c = 0, hag = 0), upper = c(r_c = 1, hag = 1), SiteDataTable = sitedata_ex_multipletrmt[[1]], DailyClimateTable = climatedata)
```

# IPCCT2

```{r}
sitedata_ex_onesite
climatedata


```

# RothC
